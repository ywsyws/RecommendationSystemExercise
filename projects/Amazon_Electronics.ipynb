{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Union\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7824482, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['cust_id', 'item_id','rating','timestamp']\n",
    "df = pd.read_csv(\"data/Amazon_Electronics_Ratings.csv\", names=cols)\n",
    "df['timestamp'] = pd.to_datetime(df.timestamp, unit='s')\n",
    "df_copy = df.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AKM1MP6P0OYPR</td>\n",
       "      <td>0132793040</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2013-04-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2CX7LUOHB2NDG</td>\n",
       "      <td>0321732944</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2NWSAGRHCP8N5</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-04-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2WNBOD3WNDNKT</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1GI0U4ZRJA8WN</td>\n",
       "      <td>0439886341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012-04-18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cust_id     item_id  rating  timestamp\n",
       "0   AKM1MP6P0OYPR  0132793040     5.0 2013-04-13\n",
       "1  A2CX7LUOHB2NDG  0321732944     5.0 2012-07-01\n",
       "2  A2NWSAGRHCP8N5  0439886341     1.0 2013-04-29\n",
       "3  A2WNBOD3WNDNKT  0439886341     3.0 2013-07-22\n",
       "4  A1GI0U4ZRJA8WN  0439886341     1.0 2012-04-18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(df: pd.DataFrame, decimal: int) -> None:\n",
    "    n_custs = df.cust_id.nunique()\n",
    "    n_items = df.item_id.nunique()\n",
    "    print(f\"Number of customers: {n_custs}\")\n",
    "    print(f\"Number of products: {n_items}\")\n",
    "    sparsity = round(1 - len(df) / (n_custs * n_items), decimal)\n",
    "    print(f\"The sparsity level of the original df is {sparsity*100}%\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers: 4201696\n",
      "Number of products: 476002\n",
      "The sparsity level of the original df is 99.9996%\n"
     ]
    }
   ],
   "source": [
    "df = df_copy.copy()\n",
    "sparsity(df, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top customers and items in terms of 'frequency'\n",
    "top_custs = (\n",
    "    df.groupby([\"cust_id\"])\n",
    "    .size()\n",
    "    .sort_values(ascending=False)[:1400000]\n",
    "    .keys()\n",
    "    .to_list()\n",
    ")\n",
    "top_items = (\n",
    "    df.groupby([\"item_id\"]).size().sort_values(ascending=False)[:5000].keys().to_list()\n",
    ")\n",
    "# filter and keep only the entries with the top customers and items\n",
    "df = df[df.cust_id.isin(top_custs) & df.item_id.isin(top_items)]\n",
    "df_reduced = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers: 1015362\n",
      "Number of products: 5000\n",
      "The sparsity level of the original df is 99.959%\n"
     ]
    }
   ],
   "source": [
    "df = df_reduced.copy()\n",
    "sparsity(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>993279</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>600478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>759467</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>266867</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>936876</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-04-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cust_id  item_id  purchase  timestamp\n",
       "184   993279        0         1 2014-07-13\n",
       "185   600478        0         1 2014-07-18\n",
       "186   759467        0         1 2014-07-22\n",
       "187   266867        0         1 2014-07-12\n",
       "188   936876        0         1 2011-04-16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_reduced.copy()\n",
    "# re-encode cust_id and item_id\n",
    "df['cust_id'] = LabelEncoder().fit_transform(df.cust_id.values)\n",
    "df['item_id'] = LabelEncoder().fit_transform(df.item_id.values)\n",
    "# converting the dataset into an implicit feedback dataset\n",
    "df['rating']  = 1\n",
    "df.rename(columns={'rating': 'purchase'}, inplace=True)\n",
    "df_cleaned = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>purchase</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7594684</th>\n",
       "      <td>822015</td>\n",
       "      <td>4904</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079596</th>\n",
       "      <td>322875</td>\n",
       "      <td>3306</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7115290</th>\n",
       "      <td>18000</td>\n",
       "      <td>4629</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723680</th>\n",
       "      <td>308061</td>\n",
       "      <td>4377</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732750</th>\n",
       "      <td>561151</td>\n",
       "      <td>1059</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cust_id  item_id  purchase  timestamp\n",
       "7594684   822015     4904         1 2014-01-16\n",
       "5079596   322875     3306         1 2014-01-27\n",
       "7115290    18000     4629         1 2014-01-11\n",
       "6723680   308061     4377         1 2014-06-04\n",
       "1732750   561151     1059         1 2010-10-10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062552, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/df_clean.csv\")\n",
    "df['timestamp'] = pd.to_datetime(df.timestamp)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df: pd.DataFrame) -> Union[pd.DataFrame]:\n",
    "    # leave one out\n",
    "    df[\"rank_latest\"] = df.groupby([\"cust_id\"])[\"timestamp\"].rank(\n",
    "        method=\"first\", ascending=False\n",
    "    )\n",
    "    train = df[df.rank_latest != 1]\n",
    "    test = df[df.rank_latest == 1]\n",
    "    \n",
    "    # keep only useful columns\n",
    "    train.drop(columns=['timestamp', 'rank_latest'], inplace=True)\n",
    "    test.drop(columns=['timestamp', 'rank_latest'], inplace=True)\n",
    "    \n",
    "    print(f'Shape of the train set: {train.shape}')\n",
    "    print(f'Shape of the test set: {test.shape}')\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train set: (1047190, 3)\n",
      "Shape of the test set: (1015362, 3)\n"
     ]
    }
   ],
   "source": [
    "# df = df_cleaned.copy()\n",
    "df_train, df_test = split_train_test(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildDataset(Dataset):\n",
    "    \"\"\"Build PyTorch Dataset for Training\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing the movie df\n",
    "        all_item_ids (list): List containing all movieIds\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, all_item_ids):\n",
    "        \"\"\"\n",
    "        Balance and initialize the training data and labels\n",
    "        \"\"\"\n",
    "        self.users, self.items, self.labels = self.generate_neg(df, all_item_ids)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of samples in the training data\n",
    "        \"\"\"\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Loads and returns a sample from the dataset with the given index.\n",
    "        \"\"\"\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]\n",
    "\n",
    "    def generate_neg(self, df, all_item_ids):\n",
    "        \"\"\"\n",
    "        Generate 4 random negative interactions for \n",
    "        every purchase (positive interaction)\n",
    "        \"\"\"\n",
    "        # training data placeholders\n",
    "        users, items, labels = [], [], []\n",
    "        # user-item interaction set that contains items that \n",
    "        # each user has interaction with\n",
    "        user_item_set = set(zip(df[\"cust_id\"], df[\"item_id\"]))\n",
    "\n",
    "        # 4:1 ratio of negative to positive samples\n",
    "        num_neg = 4 # can be tuned\n",
    "        for user, pos_item in user_item_set:\n",
    "            users.append(user)\n",
    "            items.append(pos_item)\n",
    "            labels.append(1)  # items that the user has interacted with are positive\n",
    "            for _ in range(num_neg):\n",
    "                # randomly select an item\n",
    "                neg_item = np.random.choice(all_item_ids)\n",
    "                # check that the user has not interacted with this item\n",
    "                while (user, neg_item) in user_item_set:\n",
    "                    neg_item = np.random.choice(all_item_ids)\n",
    "                users.append(user)\n",
    "                items.append(neg_item)\n",
    "                labels.append(0)  # items not interacted with are negative\n",
    "\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NCF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(pl.LightningModule):\n",
    "    \"\"\"Neural Collaborative Filtering (NCF)\n",
    "\n",
    "    Args:\n",
    "        n_custs (int): Number of unique users\n",
    "        n_items (int): Number of unique items\n",
    "        df (pd.DataFrame): Dataframe containing the movie df for training\n",
    "        all_item_ids (list): List containing all movieIds (train + test)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_custs, n_items, df, all_item_ids):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=n_custs, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=n_items, embedding_dim=8)\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.df = df\n",
    "        self.all_item_ids = all_item_ids\n",
    "\n",
    "    def forward(self, train_user, train_item):\n",
    "\n",
    "        # Pass through embedding layers\n",
    "        user_embedded = self.user_embedding(train_user)\n",
    "        item_embedded = self.item_embedding(train_item)\n",
    "\n",
    "        # Concat the two embedding layers\n",
    "        x = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "\n",
    "        # Pass through dense layer\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "\n",
    "        # Output layer\n",
    "        pred = nn.Sigmoid()(self.output(x))\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        train_user, train_item, labels = batch\n",
    "        predicted_labels = self(train_user, train_item)\n",
    "        # Use Binary Cross Entropy as criterion\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            BuildDataset(self.df, self.all_item_ids), \n",
    "            batch_size=512, num_workers=4   # can be tuned\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TQDMProgressBar(TQDMProgressBar):\n",
    "    def init_train_tqdm(self):\n",
    "        bar = super().init_train_tqdm()\n",
    "        bar.refresh_rate = 50\n",
    "        return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 8.1 M \n",
      "1 | item_embedding | Embedding | 40.0 K\n",
      "2 | fc1            | Linear    | 1.1 K \n",
      "3 | fc2            | Linear    | 2.1 K \n",
      "4 | output         | Linear    | 33    \n",
      "---------------------------------------------\n",
      "8.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "8.2 M     Total params\n",
      "32.664    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bd4ddfe8fa4063a08d64c3f6acdd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_custs = df.cust_id.nunique() + 1\n",
    "n_items = df.item_id.nunique() + 1\n",
    "# Get a list of all item IDs\n",
    "all_item_ids = df[\"item_id\"].unique()\n",
    "\n",
    "model = NCF(n_custs, n_items, df_train, all_item_ids)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=1,\n",
    "    gpus=None,\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    logger=False,\n",
    "    callbacks=[TQDMProgressBar()],\n",
    "    enable_checkpointing=False,\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_path = 'model/ncf.pt'\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation - Hit Ratio @ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = NCF(n_custs, n_items, df_train, all_item_ids)\n",
    "# model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hit Ratio @ 10 is 0.36\n",
      "CPU times: user 6h 37min 29s, sys: 15.2 s, total: 6h 37min 45s\n",
      "Wall time: 50min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# cust-item pairs for testing\n",
    "test_cust_item_set = set(zip(df_test['cust_id'], df_test['item_id']))\n",
    "\n",
    "# Dict of all items that are interacted with by each cust\n",
    "cust_interacted_items = df.groupby('cust_id')['item_id'].apply(list).to_dict()\n",
    "\n",
    "buy = []\n",
    "for (u,i) in test_cust_item_set:\n",
    "    # For each customer, randomly select 99 items that the customer has not interacted with.\n",
    "    interacted_items = cust_interacted_items[u]\n",
    "    not_interacted_items = set(all_item_ids) - set(interacted_items)\n",
    "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "    # Combine these 99 items with the test item:\n",
    "    # the actual item that the customer last interacted with.\n",
    "    # The final test item list has 100 items.\n",
    "    test_items = selected_not_interacted + [i]\n",
    "    \n",
    "    # Run the model on these 100 items\n",
    "    predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
    "                                        torch.tensor(test_items)).detach().numpy())\n",
    "    # Select the top 10 items from the list of 100 items. \n",
    "    top10_labels = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    \n",
    "    # If the test item is present within the top 10 items, \n",
    "    # then we say that this is a hit.\n",
    "    if i in top10_labels:\n",
    "        buy.append(1)\n",
    "    else:\n",
    "        buy.append(0)\n",
    "        \n",
    "print(f\"The Hit Ratio @ 10 is {np.average(buy):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('predicted_labels.npy', 'wb') as f:\n",
    "#     np.save(f, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('predicted_labels.npy', 'rb') as f:\n",
    "#     predicted_labels = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
